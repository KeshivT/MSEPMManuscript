{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSEPM Blood 450k Data Processing\n",
    "    - This notebook contains the workflow for downloading and processing 450k array data from GEO using a minfi workflow for the MSEPM Blood models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R Software Versions (R 4.1.2)\n",
    "    - LOLA_1.24.0                               \n",
    "    - FlowSorted.Blood.450k_1.32.0              \n",
    "    - IlluminaHumanMethylation450kmanifest_0.4.0\n",
    "    - minfi_1.40.0                              \n",
    "    - bumphunter_1.36.0                         \n",
    "    - locfit_1.5-9.6                            \n",
    "    - iterators_1.0.14                          \n",
    "    - foreach_1.5.2                             \n",
    "    - Biostrings_2.62.0                         \n",
    "    - XVector_0.34.0                            \n",
    "    - SummarizedExperiment_1.24.0               \n",
    "    - Biobase_2.54.0                            \n",
    "    - MatrixGenerics_1.6.0                      \n",
    "    - matrixStats_0.62.0                        \n",
    "    - GenomicRanges_1.46.1                      \n",
    "    - GenomeInfoDb_1.30.1                       \n",
    "    - IRanges_2.28.0                            \n",
    "    - S4Vectors_0.32.4                          \n",
    "    - BiocGenerics_0.40.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from ftplib import FTP\n",
    "import gzip\n",
    "import io\n",
    "import math\n",
    "import os \n",
    "import pkg_resources\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from SeriesMatrixMetaExtractor import SeriesMatrixMetaExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_info(import_diff_modules=[]):\n",
    "    '''\n",
    "    Retrieve python version and list of imported packages that \n",
    "    are imported directly or as dependencies:\n",
    "        Args:\n",
    "            import_diff_modules (List[str]): list of modules that have different install and \n",
    "                                        import names, ie scikit-learn imported with sklearn\n",
    "        Returns:\n",
    "            Dict[str, str]: package_name : version \n",
    "    '''\n",
    "    local_pkgs = {str(i).split()[0]:str(i).split()[1] for i in pkg_resources.working_set}\n",
    "    session_pkgs = {'Python':sys.version}\n",
    "    for pkg in sorted(list(set([x.split('.')[0] for x in sys.modules])) + import_diff_modules):\n",
    "        if pkg in local_pkgs:\n",
    "            session_pkgs[pkg] = local_pkgs[pkg]\n",
    "    return session_pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect session info\n",
    "session_info = get_session_info(import_diff_modules=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>3.10.4 (main, May  3 2022, 09:55:33) [GCC 11.2.0]</td>\n",
       "      <td>3.10.4 (main, May  3 2022, 09:55:33) [GCC 11.2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asttokens</th>\n",
       "      <td>2.0.5</td>\n",
       "      <td>2.0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backcall</th>\n",
       "      <td>0.2.0</td>\n",
       "      <td>0.2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cffi</th>\n",
       "      <td>1.15.0</td>\n",
       "      <td>1.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycler</th>\n",
       "      <td>0.11.0</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debugpy</th>\n",
       "      <td>1.6.0</td>\n",
       "      <td>1.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decorator</th>\n",
       "      <td>5.1.1</td>\n",
       "      <td>5.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defusedxml</th>\n",
       "      <td>0.7.1</td>\n",
       "      <td>0.7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrypoints</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executing</th>\n",
       "      <td>0.8.3</td>\n",
       "      <td>0.8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipykernel</th>\n",
       "      <td>6.13.0</td>\n",
       "      <td>6.13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipywidgets</th>\n",
       "      <td>7.7.0</td>\n",
       "      <td>7.7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jedi</th>\n",
       "      <td>0.18.1</td>\n",
       "      <td>0.18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joblib</th>\n",
       "      <td>1.1.0</td>\n",
       "      <td>1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kiwisolver</th>\n",
       "      <td>1.4.2</td>\n",
       "      <td>1.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib</th>\n",
       "      <td>3.5.2</td>\n",
       "      <td>3.5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy</th>\n",
       "      <td>1.22.3</td>\n",
       "      <td>1.22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packaging</th>\n",
       "      <td>21.3</td>\n",
       "      <td>21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas</th>\n",
       "      <td>1.4.2</td>\n",
       "      <td>1.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parso</th>\n",
       "      <td>0.8.3</td>\n",
       "      <td>0.8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pexpect</th>\n",
       "      <td>4.8.0</td>\n",
       "      <td>4.8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickleshare</th>\n",
       "      <td>0.7.5</td>\n",
       "      <td>0.7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psutil</th>\n",
       "      <td>5.9.0</td>\n",
       "      <td>5.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptyprocess</th>\n",
       "      <td>0.7.0</td>\n",
       "      <td>0.7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pyparsing</th>\n",
       "      <td>3.0.8</td>\n",
       "      <td>3.0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytz</th>\n",
       "      <td>2022.1</td>\n",
       "      <td>2022.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn</th>\n",
       "      <td>1.1.3</td>\n",
       "      <td>1.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scipy</th>\n",
       "      <td>1.8.0</td>\n",
       "      <td>1.8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seaborn</th>\n",
       "      <td>0.11.2</td>\n",
       "      <td>0.11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>1.16.0</td>\n",
       "      <td>1.16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statsmodels</th>\n",
       "      <td>0.13.5</td>\n",
       "      <td>0.13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tornado</th>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tqdm</th>\n",
       "      <td>4.64.0</td>\n",
       "      <td>4.64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traitlets</th>\n",
       "      <td>5.1.1</td>\n",
       "      <td>5.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wcwidth</th>\n",
       "      <td>0.2.5</td>\n",
       "      <td>0.2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(pd.DataFrame(session_info, index=['Package', 'Version']).T.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Procesing File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_dir = os.path.join(working_dir, 'IdatFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = os.path.join(working_dir, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file_dir = os.path.join(working_dir, 'ProcessedData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_series_dir = os.path.join(working_dir, 'SeriesMatrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in [idat_dir, processed_file_dir, \n",
    "                  exp_series_dir, tmp_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Experiment GEO Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_meta_data(file_path, platform_id):\n",
    "    with open(file_path, 'r') as meta:\n",
    "        all_exps = {}\n",
    "        exp_info = {}\n",
    "        for line in meta:\n",
    "            line_strip = line.strip()\n",
    "            if not line_strip:\n",
    "                if exp_info:\n",
    "                    all_exps[exp_info['accession_id']] = exp_info\n",
    "                exp_info = {}\n",
    "            else:\n",
    "                if not exp_info:\n",
    "                    exp_info['title'] = ' '.join(line_strip.split(' ')[1:])\n",
    "                elif '(Submitter supplied)' in line_strip:\n",
    "                    exp_info['description'] = line_strip.replace('(Submitter supplied) ', '')\n",
    "                elif 'Organism' in line_strip:\n",
    "                    exp_info['organism'] = line_strip.split(':')[1].strip()\n",
    "                elif 'Platform' in line_strip:\n",
    "                    line_split = line_strip.split(' ')\n",
    "                    exp_info['platform_id'] = platform_id\n",
    "                    exp_info['sample_number'] = int(line_split[-2])\n",
    "                elif 'FTP' in line_strip:\n",
    "                    exp_info['ftp_link'] = line_strip.split(' ')[-1]\n",
    "                elif 'Series' in line_strip:\n",
    "                    line_split = line_strip.split('\\t')\n",
    "                    exp_info['accession_id'] = line_strip.split(': ')[1].split('\\t')[0]\n",
    "    return all_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msepm_blood_exps = parse_meta_data(os.path.join(working_dir, 'UniversalBloodExps.txt'), 'GPL13534')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_exp_info(exp):\n",
    "    file_links = {}\n",
    "    raw_url = exp['ftp_link']\n",
    "    processed_link = raw_url.replace('ftp://', '').split('/')[0]\n",
    "    exp_dir = '/'.join(raw_url.replace('ftp://', '').split('/')[1:])\n",
    "    ftp = FTP(processed_link)\n",
    "    ftp.login()\n",
    "    ftp.cwd(exp_dir)\n",
    "    directories = ftp.nlst()\n",
    "    for direct in directories:\n",
    "        ftp.cwd(direct)\n",
    "        files = ftp.nlst()\n",
    "        file_links[direct] = (ftp.pwd(), files)\n",
    "        ftp.cwd('..')\n",
    "    if 'suppl' in file_links:\n",
    "        if 'filelist.txt' in file_links['suppl'][1]:\n",
    "            ftp.cwd('suppl')\n",
    "            supp_lines = []\n",
    "            ftp.retrlines('RETR filelist.txt', supp_lines.append)\n",
    "            file_links['supplemental_files'] = supp_lines\n",
    "    ftp.close()\n",
    "    return exp['accession_id'], f'ftp://{processed_link}', file_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  18 | elapsed:    7.0s remaining:   18.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  18 | elapsed:    7.0s remaining:   11.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 out of  18 | elapsed:   13.0s remaining:   13.0s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  18 | elapsed:   13.3s remaining:    8.5s\n",
      "[Parallel(n_jobs=8)]: Done  13 out of  18 | elapsed:   13.3s remaining:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  18 | elapsed:   13.3s remaining:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done  18 out of  18 | elapsed:   19.4s finished\n"
     ]
    }
   ],
   "source": [
    "processed_links = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(retrieve_exp_info)(exp) for exp in msepm_blood_exps.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_id, ftp_head, links in processed_links:\n",
    "    msepm_blood_exps[exp_id].update(links)\n",
    "    msepm_blood_exps[exp_id]['ftp_head'] = ftp_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_exps = []\n",
    "idat_sample_count = 0\n",
    "\n",
    "for exp_id, exp in msepm_blood_exps.items():\n",
    "    supp_files = exp.get('supplemental_files', [])\n",
    "    for file in supp_files:\n",
    "        if 'IDAT' in file.upper():\n",
    "            idat_exps.append(exp_id)\n",
    "            idat_sample_count += exp['sample_number']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_exp_info = {key: value for key, value in msepm_blood_exps.items() if key in idat_exps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowload series matrix files for files with IDAT files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_series_matrix(exp, output_directory):\n",
    "    matrix_head, files = exp.get('matrix', (None, None))\n",
    "    if not matrix_head:\n",
    "        return exp['accession_id']\n",
    "    else:\n",
    "        series_head = f'{exp[\"ftp_head\"]}/{matrix_head}/'\n",
    "        series_file = None\n",
    "        if len(files) == 1:\n",
    "            series_file = files[0]\n",
    "        else:\n",
    "            for file in files:\n",
    "                if exp['platform_id'].upper() in file.upper():\n",
    "                    series_file = file\n",
    "        if not series_file:\n",
    "            return exp['accession_id']\n",
    "        if os.path.exists(os.path.join(output_directory, series_file)):\n",
    "            return 0\n",
    "        wget_command = ['wget', '-q', '-nd', '-P',\n",
    "                        output_directory, f'{series_head}{series_file}']\n",
    "        p = subprocess.Popen(args=wget_command)\n",
    "        p.wait()\n",
    "        if p.returncode:\n",
    "            return exp['accession_id']\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.1569s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  18 | elapsed:    0.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  18 | elapsed:    0.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  18 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  18 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done  11 out of  18 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  13 out of  18 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  15 out of  18 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 out of  18 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "download_status = joblib.Parallel(n_jobs=16, verbose=10)(joblib.delayed(download_series_matrix)\n",
    "                                                         (*[msepm_blood_exps[exp], exp_series_dir]) for exp in idat_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Series Matrices to Extract MetaData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta(exp, series_directory):\n",
    "    matrix_head, files = exp.get('matrix', (None, None))\n",
    "    series_file = None\n",
    "    if len(files) == 1:\n",
    "        series_file = files[0]\n",
    "    else:\n",
    "        for file in files:\n",
    "            if exp['platform_id'].upper() in file.upper():\n",
    "                series_file = file\n",
    "    directory = series_directory if series_directory.endswith('/') else f'{series_directory}/'\n",
    "    series_path = f'{directory}{series_file}'\n",
    "    matrix_parser = SeriesMatrixMetaExtractor(series_matrix_path=series_path, sample_id='!Sample_geo_accession', phenotype_ids=['!Sample_characteristics_ch1'])\n",
    "    matrix_parser.get_meta_data()\n",
    "    return matrix_parser.phenotype_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1588s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  18 | elapsed:    0.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  18 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 out of  18 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  18 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  13 out of  18 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  18 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  18 out of  18 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "exp_sample_meta = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(extract_meta)(*[exp, exp_series_dir]) for exp in idat_exp_info.values())\n",
    "all_meta = {}\n",
    "for exp in exp_sample_meta:\n",
    "    all_meta.update(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Meta with File Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_idat_meta(gsm_id, gsm_info, supp_files):\n",
    "    idat_files = {}\n",
    "    for file in supp_files:\n",
    "        if gsm_id in file:\n",
    "            file_name, file_date = file.strip().split('\\t')[1:3]\n",
    "            gsm_dir = ''.join(list(gsm_id)[0:-3]) + 'nnn'\n",
    "            sample_ftp_head = f'ftp://ftp.ncbi.nlm.nih.gov/geo/samples/{gsm_dir}/{gsm_id}'\n",
    "            idat_files['ftp_head'] = sample_ftp_head\n",
    "            if 'grn' in file_name.lower():\n",
    "                idat_files['Grn'] = file_name\n",
    "            elif 'red' in file_name.lower():\n",
    "                idat_files['Red'] = file_name\n",
    "            idat_files['idat_date'] = file_date\n",
    "    return gsm_id, idat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.1344s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0061s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0015s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0018s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0036s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=2)]: Done 156 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0086s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0138s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0182s.) Setting batch_size=256.\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0329s.) Setting batch_size=512.\n",
      "[Parallel(n_jobs=2)]: Done 2556 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0590s.) Setting batch_size=1024.\n",
      "[Parallel(n_jobs=2)]: Batch computation too fast (0.0685s.) Setting batch_size=2048.\n",
      "[Parallel(n_jobs=2)]: Done 6388 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 7070 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=2)]: Done 7391 out of 7391 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "sample_idat_links = joblib.Parallel(n_jobs=2, verbose=10)(joblib.delayed(get_sample_idat_meta)\n",
    "                                                          (*[gsm_id, gsm_info, idat_exp_info[gsm_info['experiment_id']]['supplemental_files']]) for gsm_id, gsm_info in all_meta.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_sample_meta = {}\n",
    "for gsm_id, idat_links in sample_idat_links:\n",
    "    if len(idat_links) > 0:\n",
    "        sample_info = all_meta[gsm_id]\n",
    "        sample_info.update(idat_links)\n",
    "        idat_sample_meta[gsm_id] = sample_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Phenotype Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_age(gsm_meta: dict) -> bool:\n",
    "    for key in gsm_meta:\n",
    "        if 'age' in key.lower() and 'stage' not in key.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_age_meta = {key:value for key, value in idat_sample_meta.items() if search_for_age(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_age_exps = set(gsm_meta['experiment_id'] for gsm_meta in idat_age_meta.values())\n",
    "idat_exps = {key:value for key, value in idat_exp_info.items() if key in idat_age_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_sample_meta = {gsm_id: gsm_meta for gsm_id, gsm_meta in idat_sample_meta.items() if gsm_meta['experiment_id'] in idat_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbacca8d2fe64f9d8fdc0dddd40189c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_cats = set()\n",
    "ages = []\n",
    "\n",
    "for gsm_id in tqdm(idat_sample_meta):\n",
    "    gsm_meta = dict(idat_sample_meta[gsm_id].items())\n",
    "    for cat, value in gsm_meta.items():\n",
    "        if 'age' in cat.lower() and 'stage' not in cat.lower() and 'menarche' not in cat.lower():\n",
    "            if cat == 'age (days)':\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value) / 365\n",
    "                continue\n",
    "            if cat == 'fetal gestational age (weeks)':\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value) / 52.149\n",
    "                continue\n",
    "            if gsm_meta['experiment_id'] == 'GSE67444':\n",
    "                continue\n",
    "            age_cats.add(cat)\n",
    "            try:\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value)\n",
    "                ages.append(float(value))\n",
    "            except ValueError:\n",
    "                pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "sns.histplot(ages, kde=False, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download IDAT Files for all samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_idats(gsm_id, gsm_info, output_directory):\n",
    "    _grn_exists = os.path.exists(os.path.join(output_directory, gsm_info['Grn']))\n",
    "    _red_exists = os.path.exists(os.path.join(output_directory, gsm_info['Red']))\n",
    "    if _red_exists and _grn_exists:\n",
    "        return 0 \n",
    "    _grn_ftp_path = f'{gsm_info[\"ftp_head\"]}/suppl/{ gsm_info[\"Grn\"]}'\n",
    "    _red_ftp_path = f'{gsm_info[\"ftp_head\"]}/suppl/{ gsm_info[\"Red\"]}'\n",
    "    _grn_wget_command = ['wget', '-q','--limit-rate=5M', '-nd', '-P',\n",
    "                         output_directory, _grn_ftp_path]\n",
    "    _red_wget_command = ['wget', '-q','--limit-rate=5M', '-nd', '-P',\n",
    "                         output_directory, _red_ftp_path]\n",
    "    _g = subprocess.Popen(args=_grn_wget_command)\n",
    "    _r = subprocess.Popen(args=_red_wget_command)\n",
    "    _g.wait()\n",
    "    _r.wait()    \n",
    "    if _g.returncode or _r.returncode:\n",
    "        return gsm_id\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1466s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0146s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0055s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0030s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=8)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0065s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=8)]: Done 320 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0074s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=8)]: Done 560 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1072 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0081s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=8)]: Done 2032 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0121s.) Setting batch_size=256.\n",
      "[Parallel(n_jobs=8)]: Done 4336 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0186s.) Setting batch_size=512.\n",
      "[Parallel(n_jobs=8)]: Done 6228 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 6418 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 6608 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 6818 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 6986 out of 6986 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "download_status = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(download_idats)\n",
    "                                                       (*[gsm_id, gsm_info, idat_dir]) for gsm_id, gsm_info in idat_sample_meta.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate IDAT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_idat_files(gsm_meta, idat_directory):\n",
    "    idat_files = [os.path.exists(os.path.join(idat_directory, gsm_meta[\"Grn\"])),\n",
    "                  os.path.exists(os.path.join(idat_directory, gsm_meta[\"Red\"]))]\n",
    "    if not all(idat_files):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_meta = {gsm_id: gsm_meta for gsm_id, gsm_meta \n",
    "                   in idat_sample_meta.items() if not check_idat_files(gsm_meta, idat_dir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'GSE51057': 329,\n",
       "         'GSE51032': 516,\n",
       "         'GSE87571': 732,\n",
       "         'GSE125105': 699,\n",
       "         'GSE42861': 689,\n",
       "         'GSE69138': 185,\n",
       "         'GSE111629': 571,\n",
       "         'GSE128235': 537,\n",
       "         'GSE121633': 480,\n",
       "         'GSE87648': 384,\n",
       "         'GSE73103': 355,\n",
       "         'GSE61496': 312,\n",
       "         'GSE59065': 296,\n",
       "         'GSE87640': 240,\n",
       "         'GSE97362': 235,\n",
       "         'GSE156994': 219,\n",
       "         'GSE128064': 112,\n",
       "         'GSE43976': 95})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([x['experiment_id'] for x in all_sample_meta.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process IDAT Files\n",
    "- Batch samples\n",
    "    - Samples batched within experiments and all sample proccessed on same array are always in the same batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_exps = set([sample['experiment_id'] for sample in all_sample_meta.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_batches = []\n",
    "\n",
    "for exp in process_exps:\n",
    "    exp_samples = []\n",
    "    for gsm_info in all_sample_meta.values():\n",
    "        if gsm_info['experiment_id'] == exp:\n",
    "            exp_samples.append(gsm_info['Red'].replace('_Red.idat.gz', ''))\n",
    "    exp_samples.sort()\n",
    "    \n",
    "    # collect samples assayed on same array\n",
    "    chip_ids = Counter([sample.split('_')[1] for sample in exp_samples])\n",
    "    chip_size = math.ceil(np.mean(list(chip_ids.values())))\n",
    "    \n",
    "    batch_size = 60\n",
    "    while True:\n",
    "        batch_remainder = len(exp_samples) % batch_size\n",
    "        if batch_remainder < 10:\n",
    "            batch_size += chip_size\n",
    "        else:\n",
    "            break\n",
    "    ## keep samples assayed on sample chip together\n",
    "    exp_chip_samples = defaultdict(list)\n",
    "    for sample in exp_samples:\n",
    "        exp_chip_samples[sample.split('_')[1]].append(sample)\n",
    "    \n",
    "    for slide in exp_chip_samples:\n",
    "        exp_chip_samples[slide].sort(key = lambda x: x.split('_')[2])\n",
    "        \n",
    "    batch, batch_count = [], 1\n",
    "    for slide, slide_samples in exp_chip_samples.items():\n",
    "        if len(batch) + len(slide_samples) > batch_size:\n",
    "            processing_batches.append([f'{exp}_{batch_count}', batch])\n",
    "            batch = []\n",
    "            batch_count += 1\n",
    "        for sample in slide_samples:\n",
    "            batch.append(os.path.join(idat_dir, sample))\n",
    "    if batch:\n",
    "        processing_batches.append([f'{exp}_{batch_count}', batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_processing_batches = []\n",
    "\n",
    "for batch in processing_batches:\n",
    "    if len(batch[1]) < 24:\n",
    "        cleaned_processing_batches[-1][1].extend(batch[1])\n",
    "    else:\n",
    "        cleaned_processing_batches.append([batch[0], list(batch[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_batches = cleaned_processing_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrupted idat files in GEO will cause an error to be thrown if processed\n",
    "corrupted_gsm = {'GSM3668181', 'GSM2337437', 'GSM1235542'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_cmds = {}\n",
    "\n",
    "for batch in processing_batches:\n",
    "    batch_path = os.path.join(tmp_dir, f'{batch[0]}.txt')\n",
    "    with open(batch_path, 'w') as out:\n",
    "        _batch = [sample for sample in batch[1] if os.path.basename(sample).split('_')[0] not in corrupted_gsm]\n",
    "        out.write('\\n'.join(_batch))\n",
    "    batch_cmds[batch[0]] = batch_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_minfi_pipeline(minfi_pipeline_path, exp_id, ref_file_path, output_dir):\n",
    "    if os.path.exists(os.path.join(output_dir, f'{exp_id}_qc.gz')):\n",
    "        return 0, exp_id\n",
    "    cmd = ['Rscript', minfi_pipeline_path, exp_id, ref_file_path, output_dir]\n",
    "    run = subprocess.Popen(cmd)\n",
    "    run.wait()\n",
    "    return run.returncode, exp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minfi_pipe_path = os.path.join(working_dir, 'minfi_pipeline.R')\n",
    "minfi_pipe_path = os.path.join(hd, 'minfi_pipeline.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "processed = joblib.Parallel(n_jobs=4, verbose=10)(joblib.delayed(run_minfi_pipeline)(*[minfi_pipe_path, batch, \n",
    "                                                                                       batch_path, f'{processed_file_dir}/']) \n",
    "                                                  for batch, batch_path in batch_cmds.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Processed Data and Update Sample Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gzip(file_path: str, yield_indices: Union[List[int], None] = None):\n",
    "    with io.BufferedReader(gzip.open(file_path, 'rb')) as file:\n",
    "        for line in file:\n",
    "            d_line = line.decode('utf-8').strip()\n",
    "            y_line = d_line.replace('\"', '').split(',')\n",
    "            if not yield_indices:\n",
    "                yield y_line\n",
    "            else:\n",
    "                yield [y_line[index] for index in yield_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(file_path) -> dict:\n",
    "    header = None\n",
    "    meta_data = {}\n",
    "    for line in open_gzip(file_path):\n",
    "        if not header:\n",
    "            header = line[1:]\n",
    "        else:\n",
    "            sample = line[0].split('_')[0]\n",
    "            meta_data[sample] = {f'proc_{key}':convert_to_float(value) for key, value in zip(header, line[1:])}\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_batches = [batch for batch in batch_cmds.keys() if not os.path.exists(f'{processed_file_dir}/{batch}_qc.gz')]\n",
    "unprocessed_exps = set([batch.split('_')[0] for batch in unprocessed_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sample_meta = {sample:sample_info for sample, sample_info in all_sample_meta.items() if sample_info['experiment_id'] not in unprocessed_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b2c8a7b8ab4d78939a56cc958c5578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref_sample_meta = []\n",
    "\n",
    "for exp in tqdm(batch_cmds.keys()):\n",
    "    if exp in unprocessed_batches:\n",
    "        continue\n",
    "    exp_id, batch = exp.split('_')\n",
    "    qc_meta = get_meta_data(f'{processed_file_dir}/{exp}_qc.gz')\n",
    "    cell_meta = get_meta_data(f'{processed_file_dir}/{exp}_cell_counts.gz')\n",
    "    for sample in qc_meta:\n",
    "        sample_qc = qc_meta[sample]\n",
    "        proc_qc_fail = 0\n",
    "        if sample_qc['proc_mMed'] < 10.0 or sample_qc['proc_mMed'] < 10.0:\n",
    "            proc_qc_fail = 1\n",
    "        all_sample_meta[sample]['proc_qc_fail'] = proc_qc_fail\n",
    "        all_sample_meta[sample]['batch'] = batch\n",
    "        all_sample_meta[sample].update(sample_qc)\n",
    "        all_sample_meta[sample].update(cell_meta[sample])\n",
    "        all_sample_meta[sample]['processing_complete'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta = {sample:sample_info for sample, sample_info in all_sample_meta.items() if 'processing_complete' in sample_info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_tissue_sources = {'Buffy coat': 'blood',\n",
    " 'PBL': 'blood',\n",
    " 'genomic DNA extracted and purified': 'blood',\n",
    " 'Lynch-like patient. Genomic DNA': 'blood'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in sample_meta:\n",
    "    if 'X' == sample_meta[sample]['tissue_source'][0] or 'blood' in sample_meta[sample]['tissue_source'].lower():\n",
    "        proc_tissue = 'blood'\n",
    "    else:\n",
    "        proc_tissue = blood_tissue_sources.get(sample_meta[sample]['tissue_source'], 'NA')\n",
    "    sample_meta[sample]['proc_tissue'] = proc_tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{processed_file_dir}/processed_sample_meta.pkl'):\n",
    "    with open(f'{processed_file_dir}/processed_sample_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(sample_meta, out)\n",
    "    with open(f'{processed_file_dir}/processed_ref_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(ref_sample_meta, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
